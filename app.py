import streamlit as st
import openai
import pandas as pd
import os 
import sys, re
import requests

# langchain core
from langchain.text_splitter import CharacterTextSplitter
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.chains import ConversationalRetrievalChain

# langchain community
from langchain_community.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOpenAI
from langchain_community.llms import HuggingFaceHub

# í˜ì´ì§€ ë ˆì´ì•„ì›ƒì„ wideë¡œ ì§€ì •
st.set_page_config(layout="wide")
st.markdown("""
    <style>
    /* í•˜ë‹¨ "Manage app" ë§í¬ ë°‘ì¤„ ì œê±° */
    a {
        text-decoration: none !important;
    }
    </style>
""", unsafe_allow_html=True)

# CSS ì ìš© (ë²„íŠ¼ì— ì „ì²´ ì ìš©)
st.markdown("""
    <style>
    .stButton > button {
        color: white !important;
        background-color: #FF6347 !important;
        float: right;
        border: none;
    }
    .stButton > button:disabled {
        color: white !important;
        background-color: #FF6347 !important;
        opacity: 0.6;
    }
    </style>
""", unsafe_allow_html=True)

# Final Project ë¨¸ë¦¿ë§ (ì™¼ìª½ ìƒë‹¨)
st.markdown(
    "<div style='position: absolute; top: 20px; right: 20px; font-size: 14px; color: gray;'>"
    "<b>Final Project â€” <i>Understanding and Application of Foundation Models</i></b><br>"
    "</div>",
    unsafe_allow_html=True
)
st.text("\n")

# Title - Sub Title
st.markdown("<h1 style='text-align: center; color: black; padding-top: 40px;'>ChatGPT-4o Code Rule Checker</h1>", unsafe_allow_html=True)
st.markdown(
    "<h5 style='text-align: center; color: gray;'>Master of Computer Software Engineering, Yonsei University</h5>"
    "<h5 style='text-align: center; color: gray;'>Taesu Kim (2024451104)</h5>",
    unsafe_allow_html=True
)

st.text("\n")
st.text("\n")
st.text("\n")
# Create two columns
col1, col2 = st.columns(2)

# Use the columns like normal st calls
col1.subheader("[ ë°ì´í„° ì…ë ¥ ]")
col1.markdown("##### 1. ì‘ì„±í•œ ì†ŒìŠ¤ì½”ë“œ ê²€ì‚¬ë¥¼ ìœ„í•œ ë£°ì…‹ì„ ì—…ë¡œë“œí•˜ì„¸ìš”. (ìƒ˜í”Œ : java)")

# 1) get_excel_chunks ë©”ì†Œë“œ
# ì„¤ëª… : to_stringìœ¼ë¡œ ë³€í™˜ëœ ì—‘ì…€ ë°ì´í„°ë¥¼ chunks ë¡œ ìª¼ê°¬
def get_excel_chunks(data_st):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=300,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(data_st)
    return chunks

# 2) get_vectorstore ë©”ì†Œë“œ
# ì„¤ëª… : excel chunksë¥¼ ë²¡í„°í™”í•´ì„œ FAISSë¼ëŠ” ê²€ìƒ‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ì €ì¥í•¨ (ì‰½ê²Œ ë§í•´, ìª¼ê°  chunks ë“¤ì„ vector store ì— ì €ì¥í•œë‹¤ê³  ë³´ë©´ ëŒ)
def get_vectorstore(excel_text_chunks):
    embeddings = OpenAIEmbeddings(openai_api_key=os.environ["OPENAI_API_KEY"])
    vectorstore = FAISS.from_texts(texts=excel_text_chunks, embedding=embeddings)
    return vectorstore

# 3) get_conversation_chain ë©”ì†Œë“œ (í•µì‹¬ ë¡œì§, gpt-4o ì‚¬ìš©)
# ì„¤ëª… : ì‚¬ìš©ìì™€ gpt ì±—ë´‡ ê°„ì˜ ConversationalRetrievalChain ì„ ìƒì„±í•¨
#       ì´ ëŒ€í™”ì²´ì¸ì„ í†µí•´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ê¸° ìœ„í•´ ì–¸ì–´ëª¨ë¸, ë©”ëª¨ë¦¬, ë²¡í„° ê²€ìƒ‰ê¸°ë¥¼ ì‚¬ìš©í•¨
# ì°¸ê³  : RetrieverëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ì£¼ì œì— ëŒ€í•´ ë¯¸ë¦¬ í•™ìŠµëœ ë°ì´í„°ì—ì„œ ê°€ì¥ ê´€ë ¨ì´ ìˆëŠ” ì •ë³´ë¥¼ ì°¾ì•„ì£¼ëŠ” ì—­í• ì„ í•¨. ì´ê±¸ ì“°ê¸° ìœ„í•´ì„œ ë²¡í„°dbì— ì €ì¥í•´ì•¼ í•¨
def get_conversation_chain(vectorstore):
    callbacks = [StreamingStdOutCallbackHandler()]
    llm = ChatOpenAI(model="gpt-4o", openai_api_key=os.environ["OPENAI_API_KEY"], temperature=0)
    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=vectorstore.as_retriever(),
        memory=memory,
    )
    return conversation_chain

# 4) run ë©”ì†Œë“œ (ì‹¤ì œ ìµœì´ˆ ë™ì‘ë¶€)
def run():
    uploaded_file = col1.file_uploader("Choose a Excel file", type="xlsx")
    if uploaded_file is not None:
        data = pd.read_excel(uploaded_file)
        with col1.expander("ì ìš©ëœ ë£°ì…‹ì„ ìƒì„¸íˆ ë³´ê¸°"):
            keyword = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
            if keyword:
                search_result = data[data['RULE_NAME'].astype(str).str.lower().str.contains(keyword.lower())]
                st.write(search_result)
            else:
                st.write(data)
            data_st = data.to_string()
            
            excel_text_chunks = get_excel_chunks(data_st)
            vectorstore = get_vectorstore(excel_text_chunks)
            st.session_state.conversation = get_conversation_chain(vectorstore)
    else:
        col1.write("íŒŒì¼ì„ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    run()

col1.text("\n")
col1.text("\n")
col1.text("\n")
col1.markdown("##### 2. CPSP ê²€ì‚¬ë¥¼ ìœ„í•œ ì†ŒìŠ¤ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
col2.subheader("[ ê²°ê³¼ ì¶œë ¥ ]")

user_input = col1.text_area("Please enter your text here", height=600)

# 5) handle_userinput ë©”ì†Œë“œ
# ì„¤ëª… : ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì†ŒìŠ¤ì½”ë“œë¥¼ ë¼ì¸ë‹¨ìœ„ë¡œ ì½ì–´ string ì—°ì‚° í•œ ê²°ê³¼ë¥¼ ê°€ì ¸ë‹¤ê°€, ìœ„ì—ì„œ êµ¬í˜„í•œ ëŒ€í™”ì²´ì¸ì—ê²Œ ì§ˆì˜í•¨
#       ì§ˆì˜í•œ ê²°ê³¼ë¥¼ st.session_state.displayed_chat_historyì— append í•¨
def handle_userinput(check_datas):
    # ì´ì „ ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”
    st.session_state.chat_history = []  # âœ… ì¶”ê°€
    st.session_state.displayed_chat_history = []  # ì´ê±´ ì´ë¯¸ ìˆì—ˆìŒ

    # ìƒˆ ëŒ€í™” ì‹¤í–‰
    response = st.session_state.conversation({'question': check_datas})
    st.session_state.chat_history = response['chat_history']

    for i, message in enumerate(st.session_state.chat_history):
        if i % 2 != 0 and message.content not in st.session_state.displayed_chat_history:
            st.session_state.displayed_chat_history.append(message.content)

# ì˜ˆì•½ì–´ ê°•ì¡° ì œê±° í•¨ìˆ˜
def remove_highlight_from_keywords(text):
    java_keywords = [
        'System', 'String', 'Integer', 'Double', 'Boolean', 'List', 'Map', 'HashMap', 'ArrayList',
        'print', 'println', 'out', 'in', 'Math', 'Arrays'
    ]
    # ì •ê·œì‹ ê°œì„ : <mark>System.out</mark> ê°™ì€ íŒ¨í„´ë„ ëŒ€ì‘
    for kw in java_keywords:
        # ì˜ˆì•½ì–´ ì „ì²´ê°€ ê°•ì¡°ëœ ê²½ìš°
        text = re.sub(rf'<mark>{re.escape(kw)}</mark>', kw, text)
        # ì˜ˆì•½ì–´ê°€ ë§ˆì¹¨í‘œì™€ í•¨ê»˜ ê°•ì¡°ëœ ê²½ìš° (ì˜ˆ: <mark>System.out</mark>)
        text = re.sub(rf'<mark>{re.escape(kw)}\.(\w+)</mark>', rf'{kw}.\1', text)
        # ì˜ˆì•½ì–´ ì¼ë¶€ë§Œ ê°•ì¡°ëœ ê²½ìš° (ì˜ˆ: <mark>System</mark>.out.println)
        text = re.sub(rf'<mark>{re.escape(kw)}</mark>(\.\w+)', rf'{kw}\1', text)
        text = re.sub(rf'(\w+)\.<mark>{re.escape(kw)}</mark>', rf'\1.{kw}', text)
    return text

# Slack ë©”ì‹œì§€ë§Œ ë”°ë¡œ ë½‘ê¸° ìœ„í•œ í—¬í¼ í•¨ìˆ˜
def extract_slack_message(full_response):
    """
    GPTê°€ ì‘ë‹µí•œ ì „ì²´ ë©”ì‹œì§€ì—ì„œ Slack ì „ìš© í¬ë§·ë§Œ ì¶”ì¶œ
    """
    lines = full_response.splitlines()
    start_idx = next((i for i, line in enumerate(lines) if "ğŸ” *ì½”ë“œ ë£°ì…‹ ê²€ì‚¬ ê²°ê³¼*" in line), None)
    if start_idx is None:
        return "âš ï¸ Slack ë©”ì‹œì§€ í¬ë§·ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    extracted = lines[start_idx:]

    # Slackìš© ë©”ì‹œì§€ëŠ” í‘œ í˜•ì‹ì´ë¯€ë¡œ, ì „ì²´ ë¸”ë¡ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    return "\n".join(extracted).strip()

# Slack ì•Œë¦¼ ì „ì†¡ í•¨ìˆ˜
def send_to_slack(message):
    webhook_url = st.secrets["SLACK_WEBHOOK_URL"]
    payload = {
        "text": f"{message}"
    }
    response = requests.post(webhook_url, json=payload)
    if response.status_code != 200:
        st.error("Slack ì „ì†¡ ì‹¤íŒ¨: " + response.text)

if col1.button("ê²€ì‚¬ì‹œì‘", key="button"):
    with st.spinner("ê²€ì‚¬ ì¤‘ì…ë‹ˆë‹¤..."):
        st.session_state.displayed_chat_history = [] ## ì´ˆê¸°í™”
        check_data = user_input
        
        lines = check_data.splitlines()
        line_all = "\n".join(lines)

        with open('prompt/streamlit_prompt', 'r') as f:
            lines = f.readlines()
            user_query = " ".join(line.strip() for line in lines)

        check_datas = line_all + '\n' + user_query
        handle_userinput(check_datas)
        st.session_state.previous_question = line_all

        clearer = re.compile('<.*?>')
        if 'displayed_chat_history' in st.session_state:
            full_result = []
            for message in st.session_state.displayed_chat_history:
                rmT = re.sub(clearer, '', message)
                full_result.append(rmT)

            # Slack ë©”ì‹œì§€ ì¶”ì¶œ
            full_message = "\n\n".join(full_result)
            slack_message = extract_slack_message(full_message)

            # Slack ë©”ì‹œì§€ ì‹œì‘ ìœ„ì¹˜ ì œê±°
            slack_start_index = full_message.find("ğŸ”” Slack ë©”ì‹œì§€ìš© ì‘ë‹µë„ ë°˜ë“œì‹œ í•¨ê»˜ ì‘ì„±í•˜ì„¸ìš”.")
            if slack_start_index != -1:
                streamlit_only_output = full_message[:slack_start_index].strip()
            else:
                streamlit_only_output = full_message.strip()

            # âœ… Streamlitì—ì„  Slack ë‚´ìš© ì—†ì´ ì¶œë ¥
            if streamlit_only_output:
                cleaned_output = remove_highlight_from_keywords(streamlit_only_output)
                col2.markdown(cleaned_output, unsafe_allow_html=True)

            # âœ… Slackì€ ì½”ë“œë¸”ëŸ­ìœ¼ë¡œ ê°ì‹¸ì„œ ì „ì†¡
            if slack_message:
                if not slack_message.startswith("ğŸ”"):
                    slack_message = f"{slack_message}"
                send_to_slack(slack_message)

        if 'previous_question' not in st.session_state:
            st.session_state.previous_question = ""